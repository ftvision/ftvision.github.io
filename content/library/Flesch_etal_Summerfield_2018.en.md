---
draft: true
layout: paper-reading
date: 2018-11-17
title:  Comparing continual task learning in minds and machines
authors: [Flesch, Balaguer, Dekker, Nili, Summerfield, ]
year: 2018
publication: PNAS
tags: [Psych, ML, DNN]
citation: Flesch, T., Balaguer, J., Dekker, R., Nili, H., & Summerfield, C. (2018). Comparing continual task learning in minds and machines. Proceedings of the National Academy of Sciences, 115(44), E10313-E10322.
outline:Flesch and colleagues showed that grouping information and learning materials in blocks helped human to learn but imposed a disaster for Deep Neural Networks. In a categorization task, human participants learn to rules to categorize best in a full-block context and their performances decay as trial-by-trial information varies more. DNNs, however, suffer from catastrophic amnesia when information is grouped: after learning a second block, they forget everything about the first block. The authors tried to use auto-encoder to leverage the representation space in order to help DNNs to remember information in previous blocks. The attempts were not very successful, but provided some results.
categories:
- White Paper
---
