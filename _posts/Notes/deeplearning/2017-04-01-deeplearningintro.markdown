---
layout: single
title: Deep Learning
permalink: /deeplearning
---

I started to systematically learn the deep neural network architectures when I decided to take [the Deep Learning Foundations Nanodegree course at Udacity](https://www.udacity.com/degrees/deep-learning-nanodegree-foundation--nd101). It is a really introductory but comprehensive course that provide lots of materials.

The notes here are based on the course contents, but aim to extend beyond the course contents by taking other references. 

## Theoretical Background

| Content | Notes |
|:-------:|:-----:|
| Logistic Regression | Notes|
| Single Layer Perceptron | Notes |
| Activation Functions | Notes|
| BackPropogation | Notes |
| Gradient Descent | Notes | 
| Optimizers | Notes |

## Extention and Application

| Content | Notes |
|:-------:|:-----:|
| Style Transfer | Notes |
| Music Generation | Notes |

## Tools

| Content | Notes |
|:-------:|:-----:|
| Tensorflow Basics | Notes |
| TensorBoard | Notes |

## Reference 

- [Approximation Capabilities of Muitilayer
Feedforward Networks ](http://ac.els-cdn.com/089360809190009T/1-s2.0-089360809190009T-main.pdf?_tid=ffe4efe8-31b9-11e7-9053-00000aab0f6b&acdnat=1494006239_fa6fb6a9d6d27a491465ecfe426f7f3c)
- [Why deeper not wider](https://stats.stackexchange.com/questions/222883/why-are-neural-networks-becoming-deeper-but-not-wider)